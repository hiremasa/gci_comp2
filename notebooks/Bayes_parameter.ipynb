{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayes_parameter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYCZ5xH6y7O-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import time\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm as lgb\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore', UserWarning)\n",
        "from bayes_opt import BayesianOptimization\n",
        "import gc\n",
        "gc.enable()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4kq7ubSy-ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bayesian-optimization matplotlib tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxrrvNl7zEo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_path=\"\"\n",
        "print(\"Load numerical features\")\n",
        "df_num = pd.concat([\n",
        "            pd.read_feather(feature_path+\"feature_num_features.ftr\"),\n",
        "            #pd.read_feather(feature_path+\"feature_arithmetic+_combi2.ftr\"),\n",
        "            #pd.read_feather(feature_path+\"feature_arithmetic-_combi2.ftr\"),\n",
        "            pd.read_feather(feature_path+\"feature_arithmetic*_combi2.ftr\"),\n",
        "            pd.read_feather(feature_path+\"feature_arithmeticdiv_combi2.ftr\"),\n",
        "            pd.read_feather(feature_path+\"train_test_7th_df.ftr\"),\n",
        "            pd.read_feather(feature_path\"train_test_oliverFE_df.ftr\")\n",
        "            ],axis=1,)\n",
        "y_train = df_num[\"TARGET\"].dropna()\n",
        "df_num.drop([\"TARGET\"], axis=1, inplace=True)\n",
        "\n",
        "print(\"Load categorical features\")\n",
        "df = pd.concat([\n",
        "            pd.read_feather(feature_path+\"feature_1way_label_encoding_with_te.ftr\"),\n",
        "            pd.read_feather(feature_path+\"feature_2way_label_encoding_with_te.ftr\"),\n",
        "            #pd.read_feather(feature_path+\"feature_3way_including_CODE_GENDER_label_encoding_with_te.ftr\"),\n",
        "            pd.read_feather(feature_path+\"feature_round_num_label_encoding.ftr\"),\n",
        "            ],axis=1,)\n",
        "df = pd.concat([df, df_num], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IGxkc3FznJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z29bt0gvzT-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del df_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg6thrY5zoIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_path=\"\"\n",
        "y_train=pd.read_csv(input_path+\"train.csv\").TARGET"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXF48AiIzoDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=reduce_mem_usage(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNte9UNozn-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df.iloc[:y_train.shape[0],:]\n",
        "X_test = df.iloc[y_train.shape[0]:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGXAMcGgzxP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actual_imp_df=pd.read_csv(feature_path+\"actual_imp_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPZ3iv1XzxKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "null_imp_df=pd.read_csv(feature_path+\"null_imp_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9oLpBvSzxFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "THRESHOLD = 97\n",
        "\n",
        "# 閾値を超える特徴量を取得\n",
        "imp_features = []\n",
        "for feature in actual_imp_df[\"feature\"]:\n",
        "    actual_value = actual_imp_df.query(f\"feature=='{feature}'\")[\"importance\"].values\n",
        "    null_value = null_imp_df.query(f\"feature=='{feature}'\")[\"importance\"].values\n",
        "    percentage = (null_value < actual_value).sum() / null_value.size * 100\n",
        "    if percentage >= THRESHOLD:\n",
        "        imp_features.append(feature)\n",
        "len(imp_features)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zko0shbwzxDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "add_feature2=pd.read_feather(feature_path+\"github_feature2.fhr\")\n",
        "train_df=pd.concat([X_train.loc[:, imp_features], add_feature2.iloc[:y_train.shape[0],:]], axis=1)\n",
        "test_df=pd.concat([X_test.loc[:, imp_features], add_feature2.iloc[y_train.shape[0]:,:]], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kvokKQo0R6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDjv3xh90TAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNluq0Ns0Owp",
        "colab_type": "text"
      },
      "source": [
        "ベイズ最適化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn609m2_0rVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bayes_parameter_opt_lgb(X, y, init_round=25, opt_round=35, n_folds=5, random_seed=1001, n_estimators=10000, learning_rate=0.005, output_process=False):\n",
        "    # prepare data\n",
        "    train_data = lgb.Dataset(data=X, label=y,  free_raw_data=False)\n",
        "    # parameters\n",
        "\n",
        "    def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n",
        "      params = {'application':'binary','num_iterations':10000, 'learning_rate':0.005134, 'early_stopping_round':200, 'metric':'auc'}\n",
        "      params[\"num_leaves\"] = int(num_leaves)\n",
        "      params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
        "      params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
        "      params['max_depth'] = int(max_depth)\n",
        "      params['lambda_l1'] = max(lambda_l1, 0)\n",
        "      params['lambda_l2'] = max(lambda_l2, 0)\n",
        "      params['min_split_gain'] = min_split_gain\n",
        "      params['min_child_weight'] = min_child_weight\n",
        "      cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
        "      return max(cv_result['auc-mean'])\n",
        "    # range \n",
        "    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n",
        "                                            'feature_fraction': (0.1, 0.9),\n",
        "                                            'bagging_fraction': (0.8, 1),\n",
        "                                            'max_depth': (5, 8.99),\n",
        "                                            'lambda_l1': (0, 5),\n",
        "                                            'lambda_l2': (0, 3),\n",
        "                                            'min_split_gain': (0.001, 0.1),\n",
        "                                            'min_child_weight': (5, 50)}, random_state=0)\n",
        "    # optimize\n",
        "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
        "    \n",
        "    # optimize\n",
        "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
        "    \n",
        "    # output optimization process\n",
        "    if output_process==True: lgbBO.points_to_csv(feature_path+\"bayes_opt_result.csv\")\n",
        "    \n",
        "    # return best parameters\n",
        "    return lgbBO.res['max']['max_params']\n",
        "\n",
        "opt_params = bayes_parameter_opt_lgb(train_df, y_train, init_round=25, opt_round=35, n_folds=5, random_seed=1001, n_estimators=10000, learning_rate=0.005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHUHJ-gD8frN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_sp... | num_le... |"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvvzjpts0q6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(opt_params)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}