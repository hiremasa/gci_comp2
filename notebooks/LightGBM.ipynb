{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LightGBM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujSq_vG1EJTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "import time\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm as lgb\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore', UserWarning)\n",
        "\n",
        "import gc\n",
        "gc.enable()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKcYkwk0ETFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_path=\"\"\n",
        "submission_path=\"\"\n",
        "feature_path=\"\"\n",
        "print(\"Load numerical features\")\n",
        "df_num = pd.concat([\n",
        "            pd.read_feather(feature_path+\"feature_num_features.ftr\"),\n",
        "            #pd.read_feather(feature_path+\"feature_arithmetic+_combi2.ftr\"),\n",
        "            #pd.read_feather(feature_path+\"feature_arithmetic-_combi2.ftr\"),\n",
        "            pd.read_feather(feature_path+\"feature_arithmetic*_combi2.ftr\"),\n",
        "            pd.read_feather(feature_path+\"feature_arithmeticdiv_combi2.ftr\"),\n",
        "            pd.read_feather(feature_path+\"train_test_7th_df.ftr\"),\n",
        "            pd.read_feather(feature_path\"train_test_oliverFE_df.ftr\")\n",
        "            ],axis=1,)\n",
        "y_train = df_num[\"TARGET\"].dropna()\n",
        "df_num.drop([\"TARGET\"], axis=1, inplace=True)\n",
        "\n",
        "print(\"Load categorical features\")\n",
        "df = pd.concat([\n",
        "            pd.read_feather(feature_path+\"feature_1way_label_encoding_with_te.ftr\"),\n",
        "            pd.read_feather(feature_path+\"feature_2way_label_encoding_with_te.ftr\"),\n",
        "            #pd.read_feather(feature_path+\"feature_3way_including_CODE_GENDER_label_encoding_with_te.ftr\"),\n",
        "            pd.read_feather(feature_path+\"feature_round_num_label_encoding.ftr\"),\n",
        "            ],axis=1,)\n",
        "df = pd.concat([df, df_num], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwefniGNETC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc4BqiRUES-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=reduce_mem_usage(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10aB3IyKES3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df.iloc[:y_train.shape[0],:]\n",
        "X_test = df.iloc[y_train.shape[0]:,:]\n",
        "y_train=pd.read_csv(input_path+\"train.csv\").TARGET"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6G2tfEOESzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actual_imp_df=pd.read_csv(feature_path+\"actual_imp_df.csv\")\n",
        "null_imp_df=pd.read_csv(feature_path+\"null_imp_df.csv\") \n",
        "\n",
        "THRESHOLD = 97\n",
        "# 閾値を超える特徴量を取得\n",
        "imp_features = []\n",
        "for feature in actual_imp_df[\"feature\"]:\n",
        "    actual_value = actual_imp_df.query(f\"feature=='{feature}'\")[\"importance\"].values\n",
        "    null_value = null_imp_df.query(f\"feature=='{feature}'\")[\"importance\"].values\n",
        "    percentage = (null_value < actual_value).sum() / null_value.size * 100\n",
        "    if percentage >= THRESHOLD:\n",
        "        imp_features.append(feature)\n",
        "len(imp_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBENxjtSESvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "add_feature2=pd.read_feather(feature_path+\"github_feature2.fhr\")\n",
        "train_df=pd.concat([X_train.loc[:, imp_features], add_feature2.iloc[:y_train.shape[0],:]], axis=1)\n",
        "test_df=pd.concat([X_test.loc[:, imp_features], add_feature2.iloc[y_train.shape[0]:,:]], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIyJdsdZESrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oof_preds = np.zeros(train_df.shape[0]) #num feature 226 thre=97 cv=0.7639\n",
        "sub_preds = np.zeros(test_df.shape[0])\n",
        "num_folds=5\n",
        "folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
        "\n",
        "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df, y_train)):\n",
        "        train_x, train_y = train_df.iloc[train_idx], y_train.iloc[train_idx]\n",
        "        valid_x, valid_y = train_df.iloc[valid_idx], y_train.iloc[valid_idx]\n",
        "\n",
        "        # LightGBM parameters found by Bayesian optimization\n",
        "        clf = LGBMClassifier(\n",
        "            #nthread=4,\n",
        "            n_estimators=100000,\n",
        "            learning_rate=0.005134,\n",
        "            num_leaves=int(28.7),\n",
        "            feature_fraction=0.2373,\n",
        "            bagging_fraction=0.946,\n",
        "            #colsample_bytree=0.508716,\n",
        "            #subsample=0.8715623,\n",
        "            max_depth=int(5.798),\n",
        "            reg_alpha=2.605,\n",
        "            reg_lambda=0.163,\n",
        "            min_split_gain=0.07958,\n",
        "            min_child_weight=5.833,\n",
        "            silent=-1,\n",
        "            verbose=-1, )\n",
        "\n",
        "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
        "            eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n",
        "\n",
        "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
        "        sub_preds += clf.predict_proba(test_df, num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
        "\n",
        "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
        "        del clf, train_x, train_y, valid_x, valid_y\n",
        "        gc.collect()\n",
        "\n",
        "result=pd.read_csv(input_path+\"sample_submission.csv\")\n",
        "result[\"TARGET\"]=sub_preds\n",
        "result.to_csv(submission_path+\"beyascv7639_226feat_5fold_LGBM.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}